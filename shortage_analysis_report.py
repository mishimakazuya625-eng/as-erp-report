import streamlit as st
import pandas as pd
import psycopg2
from psycopg2.extras import RealDictCursor
from datetime import datetime

# --- Database Helper Functions ---
# --- Database Helper Functions ---
import time

def get_db_connection():
    max_retries = 3
    retry_delay = 1
    
    for attempt in range(max_retries):
        try:
            db_url = st.secrets["db_url"]
            # Add SSL mode if not present
            if '?' not in db_url:
                db_url += '?sslmode=require'
            elif 'sslmode' not in db_url:
                db_url += '&sslmode=require'
            conn = psycopg2.connect(db_url)
            return conn
        except (psycopg2.OperationalError, psycopg2.InterfaceError):
            if attempt < max_retries - 1:
                time.sleep(retry_delay)
                continue
            raise
        except KeyError:
            st.error("Database URL not found in secrets.")
            st.stop()

def get_filter_options():
    conn = get_db_connection()
    df=pd.read_sql_query("SELECT SITE_CODE FROM PLANT_SITE_MASTER",conn)
    conn.close()
    df.columns=df.columns.str.upper()


def perform_shortage_analysis(target_customers, target_sites, target_statuses):
    """
    Core Logic with Pre-Filtering
    """
    orders, products, bom, inventory, substitutes, snapshot_date, all_plant_sites = load_data(target_customers, target_sites, target_statuses)
    
    if orders.empty:
        return None, None, "No orders found matching the status criteria."
    if products.empty:
        return None, None, "No products found matching the customer/site criteria."
    
    # --- Step 1: Prepare Demand Data ---
    
    # Join Orders with Product Info (Inner Join applies Product filters to Orders)
    order_details = orders.merge(products, on='PN', how='inner')
    
    if order_details.empty:
        return None, None, "No matching orders found for the selected customers/sites."
    
    # Calculate Remaining Qty
    order_details['REMAINING_QTY'] = order_details['ORDER_QTY'] - order_details['DELIVERED_QTY']
    order_details['REMAINING_QTY'] = order_details['REMAINING_QTY'].clip(lower=0)
    
    # Explode BOM
    exploded = order_details.merge(bom, left_on='PN', right_on='PARENT_PN', how='inner')
    
    if exploded.empty:
        return None, None, "No BOM data found for the selected products."
    
    # Calculate Component Demand
    exploded['REQUIRED_QTY'] = exploded['REMAINING_QTY'] * exploded['BOM_QTY']
    
    # --- Step 2: URGENT Propagation ---
    # Identify which PKIDs are used in URGENT orders (within the filtered scope)
    urgent_pkids = exploded[exploded['URGENT_FLAG'] == 'Y']['CHILD_PKID'].unique()
    
    # --- Step 3: Aggregate Demand by PKID and Site ---
    demand_agg = exploded.groupby(['CHILD_PKID', 'PLANT_SITE'])['REQUIRED_QTY'].sum().reset_index()
    
    # Merge with Inventory (Site-Specific Matching)
    analysis_df = demand_agg.merge(
        inventory, 
        left_on=['CHILD_PKID', 'PLANT_SITE'], 
        right_on=['PKID', 'PLANT_SITE'], 
        how='left'
    )
    
    # Fill NaN inventory with 0
    analysis_df['PKID_QTY'] = analysis_df['PKID_QTY'].fillna(0)
    
    # Calculate Shortage
    analysis_df['SHORTAGE_QTY'] = analysis_df['REQUIRED_QTY'] - analysis_df['PKID_QTY']
    analysis_df['SHORTAGE_QTY'] = analysis_df['SHORTAGE_QTY'].clip(lower=0)
    analysis_df['IS_SHORT'] = analysis_df['SHORTAGE_QTY'] > 0
    
    # Add URGENT Flag
    analysis_df['IS_URGENT'] = analysis_df['CHILD_PKID'].isin(urgent_pkids)
    
    # --- Step 4: Generate R1 Report ---
    # R1: CUSTOMER, PLANT_SITE, ORDER_STATUS, PN, ì´ ì£¼ë¬¸ ê±´ìˆ˜, ì”ì—¬ ìˆ˜ëŸ‰ (PN), ë¶€ì¡± PKID ê°œìˆ˜, ê²°í’ˆ ë¶€í’ˆ ìƒì„¸
    
    # We need to link shortages back to the Order/Product level.
    # Join exploded with analysis_df to get shortage info for each component of each order
    r1_base = exploded.merge(
        analysis_df[['CHILD_PKID', 'PLANT_SITE', 'IS_SHORT', 'SHORTAGE_QTY']],
        on=['CHILD_PKID', 'PLANT_SITE'],
        how='left'
    )
    
    # Group by Product/Order level
    r1_report = r1_base.groupby(['CUSTOMER', 'PLANT_SITE', 'ORDER_STATUS', 'PN']).agg(
        TOTAL_ORDER_COUNT=('ORDER_KEY', 'nunique'),
        TOTAL_REMAINING_QTY=('REMAINING_QTY', 'sum'), # Sum of remaining qty for these products
        SHORT_PKID_COUNT=('CHILD_PKID', lambda x: x[r1_base.loc[x.index, 'IS_SHORT']].nunique()),
        SHORT_PKID_DETAILS=('CHILD_PKID', lambda x: ', '.join(sorted(x[r1_base.loc[x.index, 'IS_SHORT']].unique())))
    ).reset_index()
    
    # Rename columns to match request
    r1_report = r1_report.rename(columns={
        'TOTAL_ORDER_COUNT': 'ì´ ì£¼ë¬¸ ê±´ìˆ˜',
        'TOTAL_REMAINING_QTY': 'ì”ì—¬ ìˆ˜ëŸ‰ (PN)',
        'SHORT_PKID_COUNT': 'ë¶€ì¡± PKID ê°œìˆ˜',
        'SHORT_PKID_DETAILS': 'ê²°í’ˆ ë¶€í’ˆ ìƒì„¸'
    })
    
    # --- Step 5: Generate R2 Report (Wide Format) ---
    # R2: IS_URGENT, PKID, ê²°í’ˆ ë°œìƒì²˜, ì´ ì†Œìš”ëŸ‰, ì´ ì¬ê³ , ì´ ê²°í’ˆ ìˆ˜ëŸ‰, [ALL SITES] ì†Œìš”ëŸ‰, [ALL SITES] ì¬ê³ , ëŒ€ì²´í’ˆ...
    
    # Pivot for Wide Format
    # We use all_plant_sites to ensure all columns exist
    
    pivot_req = analysis_df.pivot(index='CHILD_PKID', columns='PLANT_SITE', values='REQUIRED_QTY')
    pivot_inv = analysis_df.pivot(index='CHILD_PKID', columns='PLANT_SITE', values='PKID_QTY')
    
    # Reindex with all sites (fill 0)
    pivot_req = pivot_req.reindex(columns=all_plant_sites, fill_value=0).add_suffix(' ì†Œìš”ëŸ‰')
    pivot_inv = pivot_inv.reindex(columns=all_plant_sites, fill_value=0).add_suffix(' ì¬ê³ ')
    
    r2_wide = pd.concat([pivot_req, pivot_inv], axis=1)
    
    # Summary Columns
    summary_cols = analysis_df.groupby('CHILD_PKID').agg(
        TOTAL_REQ=('REQUIRED_QTY', 'sum'),
        TOTAL_INV=('PKID_QTY', 'sum'),
        TOTAL_SHORTAGE=('SHORTAGE_QTY', 'sum'),
        IS_URGENT=('IS_URGENT', 'max')
    )
    
    # Shortage Sites
    shortage_sites = analysis_df[analysis_df['SHORTAGE_QTY'] > 0].groupby('CHILD_PKID')['PLANT_SITE'].apply(lambda x: ', '.join(x))
    summary_cols['ê²°í’ˆ ë°œìƒì²˜'] = shortage_sites
    
    # Merge
    r2_report = summary_cols.join(r2_wide, how='left')
    
    # Add Substitutes
    # Also need Substitute Inventory per site?
    # This is complex because Substitute Inventory is in Inventory_Master under SUBSTITUTE_PKID.
    # We need to query Inventory_Master for Substitute PKIDs.
    
    # Get unique substitute PKIDs
    sub_pkids = substitutes['SUBSTITUTE_PKID'].unique()
    if len(sub_pkids) > 0:
        sub_inv = inventory[inventory['PKID'].isin(sub_pkids)]
        # Aggregate sub inventory by PKID: "Site: Qty, Site: Qty"
        sub_inv['INV_STR'] = sub_inv['PLANT_SITE'] + ': ' + sub_inv['PKID_QTY'].astype(str)
        sub_inv_agg = sub_inv.groupby('PKID')['INV_STR'].apply(lambda x: ', '.join(x)).reset_index()
        sub_inv_agg.columns = ['SUBSTITUTE_PKID', 'SUB_INV_DETAILS']
        
        # Merge back to substitutes df
        substitutes_with_inv = substitutes.merge(sub_inv_agg, on='SUBSTITUTE_PKID', how='left')
        substitutes_with_inv['SUB_INV_DETAILS'] = substitutes_with_inv['SUB_INV_DETAILS'].fillna('ì¬ê³  ì—†ìŒ')
        
        # Now aggregate for R2
        subs_agg = substitutes_with_inv.groupby('CHILD_PKID').agg({
            'SUBSTITUTE_PKID': lambda x: ', '.join(x.dropna().astype(str)),
            'DESCRIPTION': lambda x: ', '.join(x.dropna().astype(str)),
            'SUB_INV_DETAILS': lambda x: ' | '.join(x.dropna().astype(str))
        }).rename(columns={
            'SUBSTITUTE_PKID': 'ì¶”ì²œ ëŒ€ì²´í’ˆ', 
            'DESCRIPTION': 'ì¶”ì²œëŒ€ì²´í’ˆ DESCRIPTION',
            'SUB_INV_DETAILS': 'ëŒ€ì²´í’ˆ ì¬ê³  í˜„í™© (SITEë³„)'
        })
        
        r2_report = r2_report.join(subs_agg, how='left')
    else:
        r2_report['ì¶”ì²œ ëŒ€ì²´í’ˆ'] = ''
        r2_report['ì¶”ì²œëŒ€ì²´í’ˆ DESCRIPTION'] = ''
        r2_report['ëŒ€ì²´í’ˆ ì¬ê³  í˜„í™© (SITEë³„)'] = ''

    # Filter: Only show items with Shortage > 0
    r2_report = r2_report[r2_report['TOTAL_SHORTAGE'] > 0]
    
    r2_report = r2_report.reset_index()
    
    # Rename Summary Columns
    r2_report = r2_report.rename(columns={
        'CHILD_PKID': 'PKID',
        'TOTAL_REQ': 'ì´ ì†Œìš”ëŸ‰',
        'TOTAL_INV': 'ì´ ì¬ê³ ',
        'TOTAL_SHORTAGE': 'ì´ ê²°í’ˆ ìˆ˜ëŸ‰'
    })
    
    # Reorder Columns
    # IS_URGENT, PKID, ê²°í’ˆ ë°œìƒì²˜, ì´ ì†Œìš”ëŸ‰, ì´ ì¬ê³ , ì´ ê²°í’ˆ ìˆ˜ëŸ‰
    fixed_cols = ['IS_URGENT', 'PKID', 'ê²°í’ˆ ë°œìƒì²˜', 'ì´ ì†Œìš”ëŸ‰', 'ì´ ì¬ê³ ', 'ì´ ê²°í’ˆ ìˆ˜ëŸ‰']
    
    # Site Columns: [Site] ì†Œìš”ëŸ‰, [Site] ì¬ê³  ...
    # We want them interleaved? Or all Req then all Inv?
    # Prompt says: [ëª¨ë“  PLANT_SITE ì½”ë“œ] ì†Œìš”ëŸ‰... [ëª¨ë“  PLANT_SITE ì½”ë“œ] ì¬ê³ ...
    # So all Req columns first, then all Inv columns.
    
    site_req_cols = [f'{site} ì†Œìš”ëŸ‰' for site in all_plant_sites]
    site_inv_cols = [f'{site} ì¬ê³ ' for site in all_plant_sites]
    
    sub_cols = ['ì¶”ì²œ ëŒ€ì²´í’ˆ', 'ì¶”ì²œëŒ€ì²´í’ˆ DESCRIPTION', 'ëŒ€ì²´í’ˆ ì¬ê³  í˜„í™© (SITEë³„)']
    
    final_cols = fixed_cols + site_req_cols + site_inv_cols + sub_cols
    
    # Ensure all columns exist
    final_cols = [c for c in final_cols if c in r2_report.columns]
    
    r2_report = r2_report[final_cols]
    
    return r1_report, r2_report, None

def show_shortage_analysis():
    st.title("ğŸš¨ ê²°í’ˆ ë¶„ì„ ë¦¬í¬íŠ¸ (Shortage Analysis)")
    
    st.info("""
    **ë¶„ì„ í”„ë¡œì„¸ìŠ¤:**
    1. **í•„í„° ì„ íƒ**: ê³ ê°ì‚¬, ìƒì‚°ì²˜, ì£¼ë¬¸ ìƒíƒœë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
    2. **ë¶„ì„ ì‹¤í–‰**: ì„ íƒëœ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ë§Œ ë¡œë“œí•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.
    3. **ê²°ê³¼ í™•ì¸**: R1(í†µí•©), R2(ìƒì„¸) ë¦¬í¬íŠ¸ë¥¼ í™•ì¸í•˜ê³  ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    """)
    
    # --- 1. Pre-Filtering UI ---
    st.subheader("1. ë¶„ì„ ëŒ€ìƒ í•„í„° (Pre-Filtering)")
    
    avail_customers, avail_sites = get_filter_options()
    
    col1, col2, col3 = st.columns(3)
    with col1:
        sel_customers = st.multiselect("ê³ ê°ì‚¬ (Customer)", avail_customers, default=avail_customers)
    with col2:
        sel_sites = st.multiselect("ìƒì‚°ì²˜ (Plant Site)", avail_sites, default=avail_sites)
    with col3:
        sel_statuses = st.multiselect("ì£¼ë¬¸ ìƒíƒœ (Order Status)", ['OPEN', 'URGENT'], default=['OPEN', 'URGENT'])
    
    # Initialize Session State
    if 'sa_r1' not in st.session_state:
        st.session_state['sa_r1'] = None
    if 'sa_r2' not in st.session_state:
        st.session_state['sa_r2'] = None
    if 'sa_error' not in st.session_state:
        st.session_state['sa_error'] = None
    if 'sa_done' not in st.session_state:
        st.session_state['sa_done'] = False
        
    # --- 2. Run Analysis ---
    if st.button("ê²°í’ˆ ë¶„ì„ ì‹¤í–‰ (Run Analysis)", type="primary"):
        if not sel_statuses:
            st.error("ì£¼ë¬¸ ìƒíƒœë¥¼ ìµœì†Œ í•˜ë‚˜ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("ë°ì´í„° ë¡œë”© ë° ë¶„ì„ ì¤‘... (Pre-Filtering Applied)"):
                r1, r2, error = perform_shortage_analysis(sel_customers, sel_sites, sel_statuses)
                
                st.session_state['sa_r1'] = r1
                st.session_state['sa_r2'] = r2
                st.session_state['sa_error'] = error
                st.session_state['sa_done'] = True
                st.rerun()
    
    # --- 3. Results ---
    if st.session_state['sa_done']:
        st.divider()
        r1 = st.session_state['sa_r1']
        r2 = st.session_state['sa_r2']
        error = st.session_state['sa_error']
        
        if error:
            st.error(error)
        else:
            # R1 Report
            st.subheader("R1. ê³ ê°ì‚¬-ìƒì‚°ì²˜ë³„ í†µí•© ê²°í’ˆ í˜„í™©")
            if r1 is not None and not r1.empty:
                st.dataframe(r1, use_container_width=True)
                csv_r1 = r1.to_csv(index=False).encode('utf-8')
                st.download_button("ğŸ“¥ R1 ë‹¤ìš´ë¡œë“œ (CSV)", csv_r1, f"R1_Shortage_{datetime.now().strftime('%Y%m%d')}.csv", "text/csv")
            else:
                st.info("ì¡°ê±´ì— ë§ëŠ” ê²°í’ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            st.divider()
            
            # R2 Report
            st.subheader("R2. í•µì‹¬ ë¶€í’ˆ ê²°í’ˆ ìš”ì•½ (Wide Format)")
            if r2 is not None and not r2.empty:
                st.dataframe(
                    r2.style.apply(lambda x: ['background-color: #ffcdd2' if x['IS_URGENT'] else '' for i in x], axis=1),
                    use_container_width=True
                )
                csv_r2 = r2.to_csv(index=False).encode('utf-8')
                st.download_button("ğŸ“¥ R2 ë‹¤ìš´ë¡œë“œ (CSV)", csv_r2, f"R2_Shortage_Detail_{datetime.now().strftime('%Y%m%d')}.csv", "text/csv")
            else:
                st.info("ì¡°ê±´ì— ë§ëŠ” ê²°í’ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
